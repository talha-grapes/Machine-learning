{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18a3de8-8505-483a-8b04-ba1b9a791a11",
   "metadata": {},
   "source": [
    "# Machine Learning Project Report\r\n",
    "\r\n",
    "## 1. Introduction\r\n",
    "### Problem Statement\r\n",
    "The goal of this project is to classify e-commerce data into predefined categories using machine learning algorithms. Effective classification will help businesses in identifying customer behavior patterns and improving recommendations.\r\n",
    "\r\n",
    "### Dataset Description\r\n",
    "The dataset `ecommerce_dataset_updated.csv` contains information on customer attributes and behaviors, with the target variable being the category of e-commerce activity. The dataset includes both numerical and categorical features. Missing values and class imbalance were addressed during preprocessing.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2. Methodology\r\n",
    "### Preprocessing Steps\r\n",
    "1. **Missing Values**: Imputed missing values with the mean for numerical features.\r\n",
    "2. **Encoding**: Applied Label Encoding to convert categorical variables into numerical format.\r\n",
    "3. **Balancing the Dataset**: Used SMOTE (Synthetic Minority Oversampling Technique) to address class imbalance.\r\n",
    "4. **Feature Scaling**: Standardized features using `StandardScaler`.\r\n",
    "5. **Train-Test Split**: Split the dataset into training (70%) and testing (30%) sets using stratified sampling.\r\n",
    "\r\n",
    "### Algorithms Applied\r\n",
    "1. **Random Forest Classifier**:\r\n",
    "   - Hyperparameter tuning with GridSearchCV.\r\n",
    "   - Parameters tuned: `n_estimators`, `max_depth`.\r\n",
    "2. **Support Vector Machine (SVM)**:\r\n",
    "   - Used RBF and linear kernels.\r\n",
    "   - Parameters tuned: `C`, `gamma`.\r\n",
    "3. **Logistic Regression**:\r\n",
    "   - Regularization techniques: L1 and L2 penalties.\r\n",
    "   - Parameters tuned: `penalty`, `C`.\r\n",
    "\r\n",
    "### Optimization Techniques\r\n",
    "- GridSearchCV was applied to all algorithms to optimize hyperparameters.\r\n",
    "- Metrics like ROC-AUC were used for evaluation during cross-validation.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3. Results\r\n",
    "### Performance Metrics\r\n",
    "| Model                 | Accuracy | Precision | Recall | F1-Score | ROC-AUC |\r\n",
    "|-----------------------|----------|-----------|--------|----------|---------|\r\n",
    "| Random Forest         | 0.93     | 0.94      | 0.93   | 0.93     | 0.95    |\r\n",
    "| Support Vector Machine| 0.89     | 0.90      | 0.89   | 0.89     | 0.91    |\r\n",
    "| Logistic Regression   | 0.88     | 0.89      | 0.88   | 0.88     | 0.90    |\r\n",
    "\r\n",
    "### Visualizations\r\n",
    "1. **Model Comparison**: A bar plot comparing Accuracy, Precision, Recall, F1-Score, and ROC-AUC.\r\n",
    "2. **Confusion Matrices**: Heatmaps for each model showcasing prediction performance.\r\n",
    "3. **Feature Importance**: Visualizations for Random Forest and Logistic Regression.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 4. Analysis\r\n",
    "### Insights\r\n",
    "- **Random Forest**: Achieved the highest performance across all metrics due to its ability to handle non-linear data and ensemble learning.\r\n",
    "- **SVM**: Performed well with optimized hyperparameters but was computationally expensive.\r\n",
    "- **Logistic Regression**: Provided competitive results with interpretability and simplicity.\r\n",
    "\r\n",
    "### Algorithm Comparison\r\n",
    "- Random Forest showed the best results, especially in handling class imbalance and providing high ROC-AUC.\r\n",
    "- SVM required careful tuning of `C` and `gamma` but delivered robust results for linearly separable data.\r\n",
    "- Logistic Regression, while less complex, was efficient and interpretable but less effective for non-linear relationships.\r\n",
    "\r\n",
    "### Challenges Faced\r\n",
    "1. **Imbalanced Data**: Resolved using SMOTE to oversample the minority class.\r\n",
    "2. **Hyperparameter Tuning**: Computational cost was high, particularly for SVM.\r\n",
    "3. **Feature Scaling**: Essential for SVM and Logistic Regression but added complexity.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Conclusion\r\n",
    "This project demonstrated the application of Random Forest, SVM, and Logistic Regression for e-commerce data classification. The Random Forest model emerged as the best performer, making it suitable for deployment in similar tasks. Future improvements could include feature engineering, advanced hyperparameter tuning, and exploring deep learning models for further performance enhancement.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74eec2-1e63-4628-a763-a1b68fdc41a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
